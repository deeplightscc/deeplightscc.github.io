<html>
<title>DeepLight: ML-Driven Robust Screen-Camera Communication for Public Displays</title>
<body>
<head>DeepLight: ML-Driven Robust Screen-Camera Communication for Public Displays</head>
<p>Click <a href="https://github.com/deeplightscc/deeplightscc.github.io"> here</a> to download material</p>
  Some materials for DeepLight <br>
  1. The images used to train DeepLight Screen Extractor <br>
  2. The representative images of videos used in the user study <br>
  3. The representative images of videos used to train DeepLight Decoder <br>
  4. The representative images of videos used in the experiment <br>
  5. A video showing DeepLight operation in real-time (demo.MP4). The DeepLight application takes 1 second of video at 120FPS and sends it to a server to decode using DeepLight full system (including DeepLight Screen Extractor and DeepLight Decoder). The server will send the text result (Alice in Wonder Land) back to the iPhone after processing it. Currently, the long delay is caused by the transmission time. Recently iPhone can run MobileNet in real-time, so we believe that it can easily run DeepLight in real-time <br>
</body>
</html>
